# å¯åŠ¨å‘½ä»¤ï¼šstreamlit run "D:\python_work\master\1\frontend\ui_2.py"
import streamlit as st
import requests
import json
from typing import Generator  # æ–°å¢ï¼šç”¨äºæµå¼ç”Ÿæˆå™¨

# åç«¯ API åœ°å€
API_URL = "http://localhost:8000"

# ========== 1. é¡µé¢é…ç½® + è‡ªåŠ¨æ»šåŠ¨ JS é€»è¾‘ ==========
st.set_page_config(
    page_title="RAG åˆ†ç¦»ç‰ˆå®¢æˆ·ç«¯",
    page_icon="ğŸ¤–",
    layout="wide"
)

# æ–°å¢ï¼šè‡ªåŠ¨æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯çš„ JS ä»£ç 
st.components.v1.html(
    """
    <script>
    function autoScroll() {
        const chatContainer = document.querySelector('[data-testid="stChatMessage"]:last-of-type');
        if (chatContainer) {
            chatContainer.scrollIntoView({ behavior: 'smooth', block: 'end' });
        }
    }
    setInterval(autoScroll, 100);
    </script>
    """,
    height=0,
    width=0
)

st.title("ğŸ¤– zhipu RAG (Client)")

# ========== 2. ä¾§è¾¹æ ï¼ˆä¿ç•™ä¸å˜ï¼‰ ==========
with st.sidebar:
    st.header("âš™ï¸ é…ç½®ä¸ç®¡ç†")
    st.subheader("æ¨¡å‹é€‰æ‹©")
    selected_model = st.selectbox(
        "é€‰æ‹©é—®ç­”æ¨¡å‹",
        options=["glm-4.5-air", "glm-3-turbo"],
        index=0,
        help="åˆ‡æ¢ä¸åŒçš„æ™ºè°±æ¨¡å‹è¿›è¡Œé—®ç­”"
    )
    st.divider()
    st.subheader("æ–‡æ¡£ä¸Šä¼ ")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£ï¼ˆPDF/TXT/DOCXï¼‰",
        type=['pdf', 'txt', 'docx'],
        help="æ”¯æŒPDFã€TXTã€Wordæ–‡æ¡£æ ¼å¼"
    )
    if uploaded_file and st.button("ğŸ“¤ ä¸Šä¼ å¹¶ç´¢å¼•", use_container_width=True):
        with st.spinner("æ­£åœ¨å‘é€è‡³åç«¯å¤„ç†..."):
            try:
                files = {"file": (uploaded_file.name, uploaded_file, uploaded_file.type)}
                response = requests.post(f"{API_URL}/api/upload", files=files)
                if response.status_code == 200:
                    data = response.json()
                    st.success(f"âœ… æˆåŠŸï¼åˆ‡åˆ†ç‰‡æ®µæ•°: {data['chunks_added']}")
                    st.rerun()
                else:
                    st.error(f"âŒ å¤±è´¥: {response.text}")
            except Exception as e:
                st.error(f"âŒ è¿æ¥åç«¯å¤±è´¥: {str(e)}")
    st.divider()
    st.subheader("å·²ä¸Šä¼ æ–‡æ¡£")
    try:
        doc_list_resp = requests.get(f"{API_URL}/api/list_documents")
        if doc_list_resp.status_code == 200:
            docs = doc_list_resp.json()
            if docs:
                for doc in docs:
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.text(f"ğŸ“„ {doc['file_name']}")
                    with col2:
                        if st.button("ğŸ—‘ï¸", key=f"del_{doc['doc_id']}"):
                            del_resp = requests.post(
                                f"{API_URL}/api/delete_document",
                                json={"doc_id": doc['doc_id']}
                            )
                            if del_resp.status_code == 200:
                                st.success("åˆ é™¤æˆåŠŸï¼")
                                st.rerun()
                            else:
                                st.error("åˆ é™¤å¤±è´¥ï¼")
            else:
                st.info("æš‚æ— å·²ä¸Šä¼ æ–‡æ¡£")
        else:
            st.error("è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥")
    except Exception as e:
        st.error(f"åŠ è½½æ–‡æ¡£åˆ—è¡¨å‡ºé”™: {str(e)}")

# ========== 3. ä¸»ç•Œé¢ï¼šæµå¼èŠå¤©ï¼ˆæ ¸å¿ƒä¿®æ­£ï¼šç§»é™¤nonlocalï¼‰ ==========
st.subheader("ğŸ’¬ æ™ºèƒ½é—®ç­”")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
# åˆå§‹åŒ–æ€è€ƒè¿‡ç¨‹å ä½ç¬¦çš„ä¼šè¯çŠ¶æ€ï¼ˆè§£å†³ä½œç”¨åŸŸé—®é¢˜ï¼‰
if "thinking_placeholder" not in st.session_state:
    st.session_state.thinking_placeholder = None

# å±•ç¤ºå†å²èŠå¤©è®°å½•
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "sources" in msg:
            with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
                for src in msg["sources"]:
                    st.text(src)

# èŠå¤©è¾“å…¥æ¡†ï¼ˆæ ¸å¿ƒä¿®æ­£ï¼šç§»é™¤nonlocalï¼Œæ”¹ç”¨ä¼šè¯çŠ¶æ€å­˜å‚¨å ä½ç¬¦ï¼‰
if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
    # 1. å±•ç¤ºç”¨æˆ·é—®é¢˜
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. è°ƒç”¨åç«¯æµå¼é—®ç­”æ¥å£
    with st.chat_message("assistant"):
        # æ€è€ƒè¿‡ç¨‹æç¤ºï¼ˆå­˜å…¥ä¼šè¯çŠ¶æ€ï¼Œè§£å†³ä½œç”¨åŸŸé—®é¢˜ï¼‰
        st.session_state.thinking_placeholder = st.empty()
        st.session_state.thinking_placeholder.markdown("æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“ä¸­çš„ç›¸å…³å†…å®¹...")


        # å®šä¹‰æµå¼ç”Ÿæˆå™¨ï¼ˆç§»é™¤nonlocalï¼Œç›´æ¥ä½¿ç”¨ä¼šè¯çŠ¶æ€çš„å ä½ç¬¦ï¼‰
        def answer_generator():
            sources = []
            full_response = ""
            try:
                # æµå¼è¯·æ±‚åç«¯
                response = requests.post(
                    f"{API_URL}/api/chat_stream",
                    json={"question": prompt, "model_name": selected_model},
                    stream=True,
                    timeout=30  # å¢åŠ è¶…æ—¶ï¼Œé¿å…å¡æ­»
                )
                if response.status_code != 200:
                    yield f"âŒ åç«¯æŠ¥é”™: {response.text}"
                    return

                # é€æ®µå¤„ç†åç«¯å“åº”ï¼ˆæ— sleepï¼Œéé˜»å¡ï¼‰
                st.session_state.thinking_placeholder.markdown(f"æ£€ç´¢å®Œæˆï¼Œæ­£åœ¨è°ƒç”¨ã€Œ{selected_model}ã€æ¨¡å‹ç”Ÿæˆå›ç­”...")
                first_chunk = True
                for chunk in response.iter_lines():
                    if chunk:
                        # æ”¶åˆ°ç¬¬ä¸€ä¸ªç‰‡æ®µï¼Œæ¸…ç©ºæ€è€ƒæç¤º
                        if first_chunk:
                            st.session_state.thinking_placeholder.empty()
                            first_chunk = False

                        # è§£æç‰‡æ®µ
                        chunk_data = json.loads(chunk.decode('utf-8'))
                        if "sources" in chunk_data:
                            sources = chunk_data["sources"]
                        else:
                            # é€tokenè¿”å›ï¼Œæ— é˜»å¡
                            token = chunk_data.get("content", "")
                            full_response += token
                            yield token  # ç”Ÿæˆå™¨è¿”å›ï¼Œç”±st.write_streamå¤„ç†

                # ä¿å­˜æœ€ç»ˆç»“æœåˆ°ä¼šè¯çŠ¶æ€
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "sources": sources
                })

                # å±•ç¤ºå‚è€ƒæ¥æºï¼ˆç”Ÿæˆå®Œæˆåï¼‰
                if sources:
                    yield "\n"  # åˆ†éš”ç¬¦
                    # æ³¨æ„ï¼šexpanderä¸èƒ½åœ¨ç”Ÿæˆå™¨é‡Œyieldï¼Œéœ€æå‰å¤„ç†
                    st.session_state["current_sources"] = sources
            except requests.exceptions.ConnectionError:
                yield "âŒ æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡ï¼Œè¯·ç¡®è®¤ backend/main.py æ˜¯å¦åœ¨è¿è¡Œï¼"
            except Exception as e:
                yield f"âŒ é—®ç­”å‡ºé”™: {str(e)}"
            finally:
                # ç¡®ä¿æ€è€ƒæç¤ºè¢«æ¸…ç©º
                if st.session_state.thinking_placeholder:
                    st.session_state.thinking_placeholder.empty()


        # å…³é”®ï¼šä½¿ç”¨st.write_streamï¼ˆStreamlitåŸç”Ÿé«˜æ•ˆæµå¼APIï¼Œæ— å¡é¡¿ï¼‰
        st.write_stream(answer_generator())

        # å±•ç¤ºå‚è€ƒæ¥æºï¼ˆç”Ÿæˆå®Œæˆåå•ç‹¬å¤„ç†ï¼‰
        if "current_sources" in st.session_state and st.session_state["current_sources"]:
            with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
                for src in st.session_state["current_sources"]:
                    st.text(src)
            # æ¸…ç©ºä¸´æ—¶å­˜å‚¨çš„æ¥æºï¼Œé¿å…ä¸‹æ¬¡å¤ç”¨
            del st.session_state["current_sources"]
